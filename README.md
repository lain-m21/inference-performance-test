# inference-performance-test
Deep Learning models inference performance test

## Todos
- `tensorflow-model-server` docker build scripts
- `tensorflow-serving` gRPC client
- `torch` serving scripts
- performance test on local
- performance test on k8s